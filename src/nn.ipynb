{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import MinibooneLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "shuffleSeed = 0\n",
    "trainSize = 0.8\n",
    "testSize = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MinibooneLoader().loadMiniboone()\n",
    "\n",
    "events = dataset.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a preprocessing pipeline\n",
    "estimators = [\n",
    "    # Standardizes and scales the dataset\n",
    "    ['scale', StandardScaler()]\n",
    "]\n",
    "pipe = Pipeline(estimators).fit(events)\n",
    "\n",
    "# Transform the data using the prepared pipeline.\n",
    "stdEvents = pipe.transform(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data has been split. Training data:\n[[ 0.04852549  0.05710245 -0.42166557 ...  0.04230077  0.08020339\n   0.0614591 ]\n [ 0.08522973  0.05787857  0.40372423 ...  0.15819105  0.06338857\n   0.0602966 ]\n [ 0.03886527  0.05797087 -0.56084576 ...  0.03024111  0.03142102\n   0.06056402]\n ...\n [ 0.06007261  0.07552737  0.02669232 ...  0.06275209  0.08296288\n   0.06197942]\n [ 0.06221417  0.06761905 -0.02986604 ...  0.07141983  0.07571434\n   0.05977339]\n [ 0.06484492  0.0546634   0.00282108 ...  0.0365456   0.03887806\n   0.0591355 ]]\n[0 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Shuffle the dataset and split into training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(stdEvents, dataset.classifications, shuffle=True, random_state=shuffleSeed, train_size=trainSize, test_size=testSize)\n",
    "\n",
    "print('Data has been split. Training data:')\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training and fitting neural network\n",
      "Iteration 1, loss = 0.44905350\n",
      "Iteration 2, loss = 0.27099337\n",
      "Iteration 3, loss = 0.25248869\n",
      "Iteration 4, loss = 0.24056195\n",
      "Iteration 5, loss = 0.23119265\n",
      "Iteration 6, loss = 0.22457859\n",
      "Iteration 7, loss = 0.22012592\n",
      "Iteration 8, loss = 0.21612475\n",
      "Iteration 9, loss = 0.21260776\n",
      "Iteration 10, loss = 0.20901799\n",
      "Iteration 11, loss = 0.20569608\n",
      "Iteration 12, loss = 0.20267556\n",
      "Iteration 13, loss = 0.20064481\n",
      "Iteration 14, loss = 0.19829653\n",
      "Iteration 15, loss = 0.19595801\n",
      "Iteration 16, loss = 0.19364552\n",
      "Iteration 17, loss = 0.19253857\n",
      "Iteration 18, loss = 0.19094063\n",
      "Iteration 19, loss = 0.18983113\n",
      "Iteration 20, loss = 0.18804426\n",
      "Iteration 21, loss = 0.18776455\n",
      "Iteration 22, loss = 0.18640499\n",
      "Iteration 23, loss = 0.18525896\n",
      "Iteration 24, loss = 0.18511755\n",
      "Iteration 25, loss = 0.18354232\n",
      "Iteration 26, loss = 0.18290478\n",
      "Iteration 27, loss = 0.18271905\n",
      "Iteration 28, loss = 0.18083950\n",
      "Iteration 29, loss = 0.18071963\n",
      "Iteration 30, loss = 0.18018836\n",
      "Iteration 31, loss = 0.18005536\n",
      "Iteration 32, loss = 0.17948415\n",
      "Iteration 33, loss = 0.17853706\n",
      "Iteration 34, loss = 0.17778497\n",
      "Iteration 35, loss = 0.17744407\n",
      "Iteration 36, loss = 0.17668598\n",
      "Iteration 37, loss = 0.17665472\n",
      "Iteration 38, loss = 0.17630716\n",
      "Iteration 39, loss = 0.17577663\n",
      "Iteration 40, loss = 0.17539762\n",
      "Iteration 41, loss = 0.17524049\n",
      "Iteration 42, loss = 0.17457828\n",
      "Iteration 43, loss = 0.17401580\n",
      "Iteration 44, loss = 0.17333879\n",
      "Iteration 45, loss = 0.17392927\n",
      "Iteration 46, loss = 0.17292735\n",
      "Iteration 47, loss = 0.17275502\n",
      "Iteration 48, loss = 0.17278040\n",
      "Iteration 49, loss = 0.17253839\n",
      "Iteration 50, loss = 0.17194813\n",
      "Iteration 51, loss = 0.17217532\n",
      "Iteration 52, loss = 0.17125758\n",
      "Iteration 53, loss = 0.17155284\n",
      "Iteration 54, loss = 0.17074592\n",
      "Iteration 55, loss = 0.17039723\n",
      "Iteration 56, loss = 0.17130458\n",
      "Iteration 57, loss = 0.17086520\n",
      "Iteration 58, loss = 0.17005451\n",
      "Iteration 59, loss = 0.16929982\n",
      "Iteration 60, loss = 0.16991416\n",
      "Iteration 61, loss = 0.17003911\n",
      "Iteration 62, loss = 0.16934824\n",
      "Iteration 63, loss = 0.16959557\n",
      "Iteration 64, loss = 0.16878415\n",
      "Iteration 65, loss = 0.16870527\n",
      "Iteration 66, loss = 0.16892120\n",
      "Iteration 67, loss = 0.16875190\n",
      "Iteration 68, loss = 0.16827053\n",
      "Iteration 69, loss = 0.16889307\n",
      "Iteration 70, loss = 0.16770334\n",
      "Iteration 71, loss = 0.16864944\n",
      "Iteration 72, loss = 0.16810483\n",
      "Iteration 73, loss = 0.16788871\n",
      "Iteration 74, loss = 0.16748716\n",
      "Iteration 75, loss = 0.16735660\n",
      "Iteration 76, loss = 0.16740484\n",
      "Iteration 77, loss = 0.16695948\n",
      "Iteration 78, loss = 0.16705765\n",
      "Iteration 79, loss = 0.16729075\n",
      "Iteration 80, loss = 0.16697707\n",
      "Iteration 81, loss = 0.16647169\n",
      "Iteration 82, loss = 0.16612779\n",
      "Iteration 83, loss = 0.16613395\n",
      "Iteration 84, loss = 0.16683997\n",
      "Iteration 85, loss = 0.16582416\n",
      "Iteration 86, loss = 0.16580321\n",
      "Iteration 87, loss = 0.16616848\n",
      "Iteration 88, loss = 0.16535918\n",
      "Iteration 89, loss = 0.16558229\n",
      "Iteration 90, loss = 0.16587635\n",
      "Iteration 91, loss = 0.16513149\n",
      "Iteration 92, loss = 0.16571841\n",
      "Iteration 93, loss = 0.16528327\n",
      "Iteration 94, loss = 0.16485154\n",
      "Iteration 95, loss = 0.16464363\n",
      "Iteration 96, loss = 0.16525396\n",
      "Iteration 97, loss = 0.16443021\n",
      "Iteration 98, loss = 0.16479034\n",
      "Iteration 99, loss = 0.16484954\n",
      "Iteration 100, loss = 0.16491348\n",
      "Iteration 101, loss = 0.16443033\n",
      "Iteration 102, loss = 0.16465947\n",
      "Iteration 103, loss = 0.16412208\n",
      "Iteration 104, loss = 0.16433112\n",
      "Iteration 105, loss = 0.16371967\n",
      "Iteration 106, loss = 0.16402196\n",
      "Iteration 107, loss = 0.16389942\n",
      "Iteration 108, loss = 0.16349248\n",
      "Iteration 109, loss = 0.16384225\n",
      "Iteration 110, loss = 0.16400682\n",
      "Iteration 111, loss = 0.16403758\n",
      "Iteration 112, loss = 0.16332810\n",
      "Iteration 113, loss = 0.16358878\n",
      "Iteration 114, loss = 0.16302339\n",
      "Iteration 115, loss = 0.16321537\n",
      "Iteration 116, loss = 0.16363145\n",
      "Iteration 117, loss = 0.16309970\n",
      "Iteration 118, loss = 0.16299087\n",
      "Iteration 119, loss = 0.16270979\n",
      "Iteration 120, loss = 0.16312306\n",
      "Iteration 121, loss = 0.16286578\n",
      "Iteration 122, loss = 0.16305925\n",
      "Iteration 123, loss = 0.16290637\n",
      "Iteration 124, loss = 0.16237113\n",
      "Iteration 125, loss = 0.16271200\n",
      "Iteration 126, loss = 0.16250415\n",
      "Iteration 127, loss = 0.16305604\n",
      "Iteration 128, loss = 0.16246894\n",
      "Iteration 129, loss = 0.16223419\n",
      "Iteration 130, loss = 0.16305437\n",
      "Iteration 131, loss = 0.16237510\n",
      "Iteration 132, loss = 0.16268480\n",
      "Iteration 133, loss = 0.16264081\n",
      "Iteration 134, loss = 0.16197550\n",
      "Iteration 135, loss = 0.16269882\n",
      "Iteration 136, loss = 0.16220862\n",
      "Iteration 137, loss = 0.16184179\n",
      "Iteration 138, loss = 0.16185976\n",
      "Iteration 139, loss = 0.16149323\n",
      "Iteration 140, loss = 0.16232306\n",
      "Iteration 141, loss = 0.16273330\n",
      "Iteration 142, loss = 0.16146598\n",
      "Iteration 143, loss = 0.16157025\n",
      "Iteration 144, loss = 0.16154233\n",
      "Iteration 145, loss = 0.16149884\n",
      "Iteration 146, loss = 0.16175604\n",
      "Iteration 147, loss = 0.16179251\n",
      "Iteration 148, loss = 0.16189170\n",
      "Iteration 149, loss = 0.16149248\n",
      "Iteration 150, loss = 0.16157646\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Classifying test data\n",
      "Confusion matrix:\n",
      "[[ 6337   933]\n",
      " [  840 17903]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      7270\n",
      "           1       0.95      0.96      0.95     18743\n",
      "\n",
      "    accuracy                           0.93     26013\n",
      "   macro avg       0.92      0.91      0.92     26013\n",
      "weighted avg       0.93      0.93      0.93     26013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layersConfig = (10, 10, 10)\n",
    "maxIterations = 1000\n",
    "\n",
    "print('Training and fitting neural network')\n",
    "mlp = MLPClassifier(hidden_layer_sizes=layersConfig, max_iter=maxIterations, verbose=True)\n",
    "mlp.fit(X_train, y_train.ravel())\n",
    "print('\\nTraining complete\\n')\n",
    "\n",
    "print('Classifying test data')\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}